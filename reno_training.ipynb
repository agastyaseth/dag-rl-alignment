{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import logging\n",
    "import json\n",
    "import math\n",
    "import random\n",
    "import diffusers\n",
    "import transformers\n",
    "from pathlib import Path\n",
    "from packaging import version\n",
    "from copy import deepcopy\n",
    "\n",
    "from dataset import (\n",
    "    ImageTextDataset,\n",
    "    LengthGroupedVideoTextDataset,\n",
    "    create_image_text_dataloaders,\n",
    "    create_length_grouped_video_text_dataloader\n",
    ")\n",
    "\n",
    "from pyramid_dit import (\n",
    "    PyramidDiTForVideoGeneration,\n",
    "    JointTransformerBlock,\n",
    "    FluxSingleTransformerBlock,\n",
    "    FluxTransformerBlock,\n",
    ")\n",
    "\n",
    "from trainer_misc import (\n",
    "    init_distributed_mode, \n",
    "    setup_for_distributed, \n",
    "    create_optimizer,\n",
    "    train_one_epoch_with_fsdp,\n",
    "    constant_scheduler,\n",
    "    cosine_scheduler,\n",
    ")\n",
    "\n",
    "from trainer_misc import (\n",
    "    is_sequence_parallel_initialized,\n",
    "    init_sequence_parallel_group,\n",
    "    get_sequence_parallel_proc_num,\n",
    "    init_sync_input_group,\n",
    "    get_sync_input_group,\n",
    ")\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import (\n",
    "    FullOptimStateDictConfig, \n",
    "    FullStateDictConfig,\n",
    "    ShardedOptimStateDictConfig,\n",
    "    ShardedStateDictConfig,\n",
    "    ShardingStrategy,\n",
    "    BackwardPrefetch,\n",
    "    MixedPrecision,\n",
    "    CPUOffload,\n",
    "    StateDictType,\n",
    ")\n",
    "\n",
    "from torch.distributed.fsdp.wrap import ModuleWrapPolicy, size_based_auto_wrap_policy\n",
    "from transformers.models.clip.modeling_clip import CLIPEncoderLayer\n",
    "from transformers.models.t5.modeling_t5 import T5Block\n",
    "\n",
    "import accelerate\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import DistributedType, ProjectConfiguration, set_seed\n",
    "from accelerate import FullyShardedDataParallelPlugin\n",
    "from diffusers.utils import is_wandb_available\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.state import AcceleratorState\n",
    "from diffusers.optimization import get_scheduler\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser('Pyramid-Flow Multi-process Training script', add_help=False)\n",
    "    parser.add_argument('--task', default='t2v', type=str, choices=[\"t2v\", \"t2i\"], help=\"Training image generation or video generation\")\n",
    "    parser.add_argument('--batch_size', default=4, type=int, help=\"The per device batch size\")\n",
    "    parser.add_argument('--epochs', default=100, type=int)\n",
    "    parser.add_argument('--print_freq', default=20, type=int)\n",
    "    parser.add_argument('--iters_per_epoch', default=2000, type=int)\n",
    "    parser.add_argument('--save_ckpt_freq', default=20, type=int)\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--ema_update', action='store_true')\n",
    "    parser.add_argument('--ema_decay', default=0.9999, type=float, metavar='MODEL', help='ema decay rate')\n",
    "    parser.add_argument('--load_ema_model', default='', type=str, help='The ema model checkpoint loading')\n",
    "    parser.add_argument('--model_name', default='pyramid_flux', type=str, help=\"The Model Architecture Name\", choices=[\"pyramid_flux\", \"pyramid_mmdit\"])\n",
    "    parser.add_argument('--model_path', default='', type=str, help='The pre-trained dit weight path')\n",
    "    parser.add_argument('--model_variant', default='diffusion_transformer_384p', type=str, help='The dit model variant', choices=['diffusion_transformer_768p', 'diffusion_transformer_384p', 'diffusion_transformer_image'])\n",
    "    parser.add_argument('--model_dtype', default='bf16', type=str, help=\"The Model Dtype: bf16 or fp16\", choices=['bf16', 'fp16'])\n",
    "    parser.add_argument('--load_model_ema_to_cpu', action='store_true')\n",
    "\n",
    "    # FSDP condig\n",
    "    parser.add_argument('--use_fsdp', action='store_true')\n",
    "    parser.add_argument('--fsdp_shard_strategy', default='zero2', type=str, choices=['zero2', 'zero3'])\n",
    "\n",
    "    # The training manner config\n",
    "    parser.add_argument('--use_flash_attn', action='store_true')\n",
    "    parser.add_argument('--use_temporal_causal', action='store_true', default=True)\n",
    "    parser.add_argument('--interp_condition_pos', action='store_true', default=True)\n",
    "    parser.add_argument('--sync_video_input', action='store_true', help=\"whether to sync the video input\")\n",
    "    parser.add_argument('--load_text_encoder', action='store_true', help=\"whether to load the text encoder during training\")\n",
    "    parser.add_argument('--load_vae', action='store_true', help=\"whether to load the video vae during training\")\n",
    "\n",
    "    # Sequence Parallel config\n",
    "    parser.add_argument('--use_sequence_parallel', action='store_true')\n",
    "    parser.add_argument('--sp_group_size', default=1, type=int, help=\"The group size of sequence parallel\")\n",
    "    parser.add_argument('--sp_proc_num', default=-1, type=int, help=\"The number of process used for video training, default=-1 means using all process. This args indicated using how many processes for video training\")\n",
    "\n",
    "    # Model input config\n",
    "    parser.add_argument('--max_frames', default=16, type=int, help='number of max video frames')\n",
    "    parser.add_argument('--frame_per_unit', default=1, type=int, help=\"The number of frames per training unit\")\n",
    "    parser.add_argument('--schedule_shift', default=1.0, type=float, help=\"The flow matching schedule shift\")\n",
    "    parser.add_argument('--corrupt_ratio', default=1/3, type=float, help=\"The corruption ratio for the clean history in AR training\")\n",
    "\n",
    "    # Dataset Cconfig\n",
    "    parser.add_argument('--anno_file', default='', type=str, help=\"The annotation jsonl file\")\n",
    "    parser.add_argument('--resolution', default='384p', type=str, help=\"The input resolution\", choices=['384p', '768p'])\n",
    "\n",
    "    # Training set config\n",
    "    parser.add_argument('--dit_pretrained_weight', default='', type=str, help='The pretrained dit checkpoint')  \n",
    "    parser.add_argument('--vae_pretrained_weight', default='', type=str,)\n",
    "    parser.add_argument('--not_add_normalize', action='store_true')\n",
    "    parser.add_argument('--use_temporal_pyramid', action='store_true', help=\"Whether to use the AR temporal pyramid training for video generation\")\n",
    "    parser.add_argument('--gradient_checkpointing', action='store_true')\n",
    "    parser.add_argument('--gradient_checkpointing_ratio', type=float, default=0.75, help=\"The ratio of transformer blocks used for gradient_checkpointing\")\n",
    "    parser.add_argument('--gradient_accumulation_steps', default=1, type=int, help=\"Number of updates steps to accumulate before performing a backward/update pass.\")\n",
    "    parser.add_argument('--video_sync_group', default=8, type=int, help=\"The number of process that accepts the same input video, used for temporal pyramid AR training. \\\n",
    "        This contributes to stable AR training. We recommend to set this value to 4, 8 or 16. If you have enough GPUs, set it equals to max_frames (16 for 5s, 32 for 10s), \\\n",
    "            make sure to satisfy `max_frames % video_sync_group == 0`\")\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--opt', default='adamw', type=str, metavar='OPTIMIZER',\n",
    "                        help='Optimizer (default: \"adamw\"')\n",
    "    parser.add_argument('--opt_eps', default=1e-8, type=float, metavar='EPSILON',\n",
    "                        help='Optimizer Epsilon (default: 1e-8)')\n",
    "    parser.add_argument('--opt_beta1', default=0.9, type=float, metavar='BETA1',\n",
    "                        help='Optimizer Betas (default: None, use opt default)')\n",
    "    parser.add_argument('--opt_beta2', default=0.999, type=float, metavar='BETA2',\n",
    "                        help='Optimizer Betas (default: None, use opt default)')\n",
    "    parser.add_argument('--clip_grad', type=float, default=None, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4,\n",
    "                        help='weight decay (default: 1e-4)')\n",
    "\n",
    "    parser.add_argument('--lr', type=float, default=5e-5, metavar='LR',\n",
    "                        help='learning rate (default: 5e-5)')\n",
    "    parser.add_argument('--warmup_lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='warmup learning rate (default: 1e-6)')\n",
    "    parser.add_argument('--min_lr', type=float, default=1e-5, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
    "    parser.add_argument(\n",
    "        \"--lr_scheduler\", type=str, default=\"constant_with_warmup\",\n",
    "        help=(\n",
    "            'The scheduler type to use. Choose between [\"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\",'\n",
    "            ' \"constant\", \"constant_with_warmup\"]'\n",
    "        ),\n",
    "    )\n",
    "    parser.add_argument('--warmup_epochs', type=int, default=1, metavar='N',\n",
    "                        help='epochs to warmup LR, if scheduler supports')\n",
    "    parser.add_argument('--warmup_steps', type=int, default=-1, metavar='N',\n",
    "                        help='epochs to warmup LR, if scheduler supports')\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--output_dir', type=str, default='',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--logging_dir', type=str, default='log', help='path where to tensorboard log')\n",
    "    parser.add_argument(\n",
    "        \"--report_to\",\n",
    "        type=str,\n",
    "        default=\"tensorboard\",\n",
    "        help=(\n",
    "            'The integration to report the results and logs to. Supported platforms are `\"tensorboard\"`'\n",
    "            ' (default), `\"wandb\"` and `\"comet_ml\"`. Use `\"all\"` to report to all integrations.'\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # Distributed Training parameters\n",
    "    parser.add_argument('--device', default='cuda', type=str,\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--auto_resume', action='store_true')\n",
    "    parser.set_defaults(auto_resume=True)\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--global_step', default=0, type=int, metavar='N', help='The global optimization step')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--pin_mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no_pin_mem', action='store_false', dest='pin_mem',\n",
    "                        help='')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "    \n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--local_rank', default=-1, type=int)\n",
    "    parser.add_argument('--dist_on_itp', action='store_true')\n",
    "    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training', type=str)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def build_model_runner(args):\n",
    "    model_dtype = args.model_dtype\n",
    "    model_path = args.model_path\n",
    "    model_name = args.model_name\n",
    "    model_variant = args.model_variant\n",
    "\n",
    "    print(f\"Load the {model_name} model checkpoint from path: {model_path}, using dtype {model_dtype}\")\n",
    "    sample_ratios = [1, 2, 1]  # The sample_ratios of each stage\n",
    "    assert args.batch_size % int(sum(sample_ratios)) == 0, \"The batchsize should be diivided by sum(sample_ratios)\"\n",
    "\n",
    "    runner = PyramidDiTForVideoGeneration(\n",
    "        model_path,\n",
    "        model_dtype,\n",
    "        model_name=model_name,\n",
    "        use_gradient_checkpointing=args.gradient_checkpointing,\n",
    "        gradient_checkpointing_ratio=args.gradient_checkpointing_ratio,\n",
    "        return_log=True,\n",
    "        model_variant=model_variant,\n",
    "        timestep_shift=args.schedule_shift,\n",
    "        stages=[1, 2, 4],      # using 3 stages\n",
    "        stage_range=[0, 1/3, 2/3, 1],\n",
    "        sample_ratios=sample_ratios,     # The sample proportion in a training batch\n",
    "        use_mixed_training=True,\n",
    "        use_flash_attn=args.use_flash_attn,\n",
    "        load_text_encoder=args.load_text_encoder,\n",
    "        load_vae=args.load_vae,\n",
    "        max_temporal_length=args.max_frames,\n",
    "        frame_per_unit=args.frame_per_unit,\n",
    "        use_temporal_causal=args.use_temporal_causal,\n",
    "        corrupt_ratio=args.corrupt_ratio,\n",
    "        interp_condition_pos=args.interp_condition_pos,\n",
    "        video_sync_group=args.video_sync_group,\n",
    "    )\n",
    "    \n",
    "    if args.dit_pretrained_weight:\n",
    "        dit_pretrained_weight = args.dit_pretrained_weight\n",
    "        print(f\"Loading the pre-trained DiT checkpoint from {dit_pretrained_weight}\")\n",
    "        runner.load_checkpoint(dit_pretrained_weight)\n",
    "\n",
    "    if args.vae_pretrained_weight:\n",
    "        vae_pretrained_weight = args.vae_pretrained_weight\n",
    "        print(f\"Loading the pre-trained VAE checkpoint from {vae_pretrained_weight}\")\n",
    "        runner.load_vae_checkpoint(vae_pretrained_weight)\n",
    "\n",
    "    return runner\n",
    "\n",
    "\n",
    "def auto_resume(args, accelerator):\n",
    "    if len(args.resume) > 0:\n",
    "        path = args.resume\n",
    "    else:\n",
    "        # Get the most recent checkpoint\n",
    "        dirs = os.listdir(args.output_dir)\n",
    "        dirs = [d for d in dirs if d.startswith(\"checkpoint\")]\n",
    "        dirs = sorted(dirs, key=lambda x: int(x.split(\"-\")[1]))\n",
    "        path = dirs[-1] if len(dirs) > 0 else None\n",
    "\n",
    "    if path is None:\n",
    "        accelerator.print(\n",
    "            f\"Checkpoint does not exist. Starting a new training run.\"\n",
    "        )\n",
    "        initial_global_step = 0\n",
    "    else:\n",
    "        accelerator.print(f\"Resuming from checkpoint {path}\")\n",
    "        accelerator.load_state(os.path.join(args.output_dir, path))\n",
    "        global_step = int(path.split(\"-\")[1])\n",
    "        initial_global_step = global_step\n",
    "    \n",
    "    return initial_global_step\n",
    "\n",
    "\n",
    "def build_fsdp_plugin(args):\n",
    "    fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "        sharding_strategy=ShardingStrategy.SHARD_GRAD_OP if args.fsdp_shard_strategy == 'zero2' else ShardingStrategy.FULL_SHARD,\n",
    "        backward_prefetch=BackwardPrefetch.BACKWARD_PRE,\n",
    "        auto_wrap_policy=ModuleWrapPolicy([FluxSingleTransformerBlock, FluxTransformerBlock, JointTransformerBlock, T5Block, CLIPEncoderLayer]),\n",
    "        cpu_offload=CPUOffload(offload_params=False),\n",
    "        state_dict_type=StateDictType.FULL_STATE_DICT,\n",
    "        state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=True),\n",
    "        optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=True),\n",
    "    )\n",
    "    return fsdp_plugin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train.train_pyramid_flow import get_args, build_model_runner, auto_resume, build_fsdp_plugin\n",
    "from reno_trainer import LatentNoiseTrainer  # Assuming you put the ReNO class code in reno_trainer.py\n",
    "\n",
    "reward_losses = [YourRewardLoss1(), YourRewardLoss2()]  # Define reward functions here\n",
    "reno_trainer = LatentNoiseTrainer(\n",
    "    reward_losses=reward_losses,\n",
    "    model=runner.dit,  # The T2I diffusion model\n",
    "    n_iters=10,  # Number of optimization iterations per step\n",
    "    n_inference_steps=50,  # Number of inference steps\n",
    "    seed=args.seed,\n",
    "    device=device,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
